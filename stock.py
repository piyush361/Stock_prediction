# -*- coding: utf-8 -*-
"""Stock.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19QakWYymmLLG_bInr80GT6Et-9-HCOM4
"""

import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np




stock1 = yf.Ticker("AAPL")
data1 = stock1.history(start='2010-12-24',end='2024-12-24',interval='1d')
data1.to_csv("AAPL.csv")

stock2 = yf.Ticker("AMZN")
data2 = stock2.history(start='2010-12-24',end='2024-12-24',interval='1d')
data2.to_csv("AMZN.csv")

stock3 = yf.Ticker("WFC")
data3 = stock3.history(start='2010-12-24',end='2024-12-24',interval='1d')
data3.to_csv("WFC.csv")

stock4 = yf.Ticker("TSLA")
data4 = stock4.history(start='2010-12-24',end='2024-12-24',interval='1d')
data4.to_csv("TSLA.csv")

stock5 = yf.Ticker("PFE")
data5 = stock5.history(start='2010-12-24',end='2024-12-24',interval='1d')
data1.to_csv("PFE.csv")

df1=pd.read_csv("AAPL.csv")
df2=pd.read_csv("AMZN.csv")
df3=pd.read_csv("WFC.csv")
df4=pd.read_csv("TSLA.csv")
df5=pd.read_csv("PFE.csv")



d1=df1
d2=df2
d3=df3
d4=df4
d5=df5

df1['SMA_50'] = df1['Close'].rolling(window=50).mean()
df2['SMA_50'] = df2['Close'].rolling(window=50).mean()
df3['SMA_50'] = df3['Close'].rolling(window=50).mean()
df4['SMA_50'] = df4['Close'].rolling(window=50).mean()
df5['SMA_50'] = df5['Close'].rolling(window=50).mean()

first_50 = df1['Close'][:50].mean()
df1.fillna(first_50, inplace=True)

first2_50 = df2['Close'][:50].mean()
df2.fillna(first2_50, inplace=True)

first3_50 = df3['Close'][:50].mean()
df3.fillna(first3_50, inplace=True)

first4_50 = df4['Close'][:50].mean()
df4.fillna(first4_50, inplace=True)

first5_50 = df5['Close'][:50].mean()
df5.fillna(first5_50, inplace=True)

df1['SMA_200'] = df1['Close'].rolling(window=200).mean()
df2['SMA_200'] = df2['Close'].rolling(window=200).mean()
df3['SMA_200'] = df3['Close'].rolling(window=200).mean()
df4['SMA_200'] = df4['Close'].rolling(window=200).mean()
df5['SMA_200'] = df5['Close'].rolling(window=200).mean()

first = df1['Close'][:200].mean()
df1.fillna(first, inplace=True)

first2 = df2['Close'][:200].mean()
df2.fillna(first2, inplace=True)

first3 = df3['Close'][:200].mean()
df3.fillna(first3, inplace=True)

first4 = df4['Close'][:200].mean()
df4.fillna(first4, inplace=True)

first5= df5['Close'][:200].mean()
df5.fillna(first5, inplace=True)

def calculate_indicators(df, rsi_period=14, macd_fast=12, macd_slow=26, macd_signal=9):
    if 'Close' not in df.columns:
        raise ValueError("DataFrame must contain a 'Close' column")

    df['Price Change'] = df['Close'].diff()
    df['Gain'] = df['Price Change'].where(df['Price Change'] > 0, 0)
    df['Loss'] = -df['Price Change'].where(df['Price Change'] < 0, 0)

    df['Avg Gain'] = df['Gain'].rolling(window=rsi_period).mean()
    df['Avg Loss'] = df['Loss'].rolling(window=rsi_period).mean()

    df['RS'] = df['Avg Gain'] / df['Avg Loss']
    df['RSI'] = 100 - (100 / (1 + df['RS']))

    df['EMA12'] = df['Close'].ewm(span=macd_fast, adjust=False).mean()
    df['EMA26'] = df['Close'].ewm(span=macd_slow, adjust=False).mean()

    df['MACD'] = df['EMA12'] - df['EMA26']
    df['Signal Line'] = df['MACD'].ewm(span=macd_signal, adjust=False).mean()

    return df[['Close', 'RSI', 'MACD', 'Signal Line']]

df1=calculate_indicators(df1)
df2=calculate_indicators(df2)
df3=calculate_indicators(df3)
df4=calculate_indicators(df4)
df5=calculate_indicators(df5)

df1['RSI'] = df1['RSI'].fillna(50)
df2['RSI'] = df2['RSI'].fillna(50)
df3['RSI'] = df3['RSI'].fillna(50)
df4['RSI'] = df4['RSI'].fillna(50)
df5['RSI'] = df5['RSI'].fillna(50)

from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

company_dfs = {
    "Apple": df1,
    "Amazon": df2,
    "Wells": df3,
    "Tesla": df4,
    "Pfizer": df5,
}

scalers = {}
train_test_data = {}

for company, df in company_dfs.items():
    scaler = MinMaxScaler()

    features = ['Close', 'RSI', 'MACD', 'Signal Line']
    df[features] = scaler.fit_transform(df[features])

    scalers[company] = scaler

    train_size = int(len(df) * 0.80)
    train_data = df.iloc[:train_size]
    test_data = df.iloc[train_size:]

    train_test_data[company] = {
        "train": train_data,
        "test": test_data
    }

for company, data in train_test_data.items():
    print(f"{company}: Train size = {len(data['train'])}, Test size = {len(data['test'])}")

xtrain_a = train_test_data['Apple']['train']
ytrain_a = xtrain_a['Close']
xtest_a = train_test_data['Apple']['test']
ytest_a = xtest_a['Close']

xtrain_b = train_test_data['Amazon']['train']
ytrain_b = xtrain_b['Close']
xtest_b = train_test_data['Amazon']['test']
ytest_b = xtest_b['Close']

xtrain_c = train_test_data['Wells']['train']
ytrain_c = xtrain_c['Close']
xtest_c = train_test_data['Wells']['test']
ytest_c = xtest_c['Close']

xtrain_d = train_test_data['Tesla']['train']
ytrain_d = xtrain_d['Close']
xtest_d = train_test_data['Tesla']['test']
ytest_d = xtest_d['Close']

xtrain_e = train_test_data['Pfizer']['train']
ytrain_e = xtrain_e['Close']
xtest_e = train_test_data['Tesla']['test']
ytest_e = xtest_e['Close']

X_train_dict = {'Apple': xtrain_a, 'Amazon': xtrain_b, 'Wells': xtrain_c, 'Tesla': xtrain_d, 'Pfizer': xtrain_e}
X_test_dict = {'Apple': xtest_a, 'Amazon': xtest_b, 'Wells': xtest_c, 'Tesla': xtest_d, 'Pfizer': xtest_e}
y_train_dict = {'Apple': ytrain_a, 'Amazon': ytrain_b, 'Wells': ytrain_c, 'Tesla': ytrain_d, 'Pfizer': ytrain_e}
y_test_dict = {'Apple': ytest_a, 'Amazon': ytest_b, 'Wells': ytest_c, 'Tesla': ytest_d, 'Pfizer': ytest_e}

"""**MODEL ARCHITECTURE AND OTHER FUNCTIONS**

"""

import torch
import torch.nn as nn
import math

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.encoding = torch.zeros(max_len, d_model)
        positions = torch.arange(0, max_len).unsqueeze(1).float()
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        self.encoding[:, 0::2] = torch.sin(positions * div_term)
        self.encoding[:, 1::2] = torch.cos(positions * div_term)
        self.encoding = self.encoding.unsqueeze(0)

    def forward(self, x):
        seq_len = x.size(1)
        return x + self.encoding[:, :seq_len, :].to(x.device)

class TransformerStockPredictor(nn.Module):
    def __init__(self, input_dim, seq_len, d_model, n_heads, n_encoders, ff_dim, dropout=0.1):
        super(TransformerStockPredictor, self).__init__()
        self.input_proj = nn.Linear(input_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model, max_len=seq_len)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=n_heads,
            dim_feedforward=ff_dim,
            dropout=dropout,
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_encoders)


        self.fc_out = nn.Sequential(
            nn.Linear(d_model * seq_len, d_model),
            nn.ReLU(),
            nn.Linear(d_model, 1)
        )

    def forward(self, x):
        x = self.input_proj(x)
        x = self.pos_encoder(x)

        x = self.transformer_encoder(x)

        x = x.view(x.size(0), -1)
        return self.fc_out(x)

import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import os

import torch
import torch.nn.functional as F

class StockDataset(torch.utils.data.Dataset):
    def __init__(self, X, y, seq_len, batch_size, pad_value=0.0):

        if isinstance(X, pd.DataFrame):
            X = X.values
        if isinstance(y, pd.Series):
            y = y.values

        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.float32)
        self.seq_len = seq_len
        self.batch_size = batch_size
        self.pad_value = pad_value

        # Ensure X and y are 2D
        if self.X.ndimension() == 1:  # For single feature case
            self.X = self.X.unsqueeze(1)  # Add second dimension for features
        if self.y.ndimension() == 1:  # For single feature case
            self.y = self.y.unsqueeze(1)  # Ensure y has shape (num_samples, 1)

        self.X_padded = self._pad_sequences(self.X)
        self.y_padded = self._pad_sequences(self.y)

    def _pad_sequences(self, data):
        total_len = len(data)
        remainder = (total_len % self.seq_len)

        if remainder != 0:
            pad_len = self.seq_len - remainder
            data = torch.cat((data, torch.full((pad_len, data.shape[1]), self.pad_value)), dim=0)

        total_len = len(data)
        if total_len % self.batch_size != 0:
            batch_pad_len = (self.batch_size - (total_len % self.batch_size)) % self.batch_size
            data = torch.cat((data, torch.full((batch_pad_len, data.shape[1]), self.pad_value)), dim=0)

        return data

    def __len__(self):
        return len(self.X_padded) // self.seq_len

    def __getitem__(self, idx):
        start = idx * self.seq_len
        end = start + self.seq_len
        x_seq = self.X_padded[start:end]
        y_seq = self.y_padded[start:end]
        return x_seq, y_seq

import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader

def train_models_with_saving(X_train_dict, y_train_dict, X_test_dict, y_test_dict, seq_len, model_params, epochs=2, lr=1e-3, batch_size=32, save_dir='./models'):
    """
    Train models for multiple companies and save them.
    Returns a dictionary of trained models.
    """
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    trained_models = {}

    for company, X_train in X_train_dict.items():
        print(f"\nTraining model for {company}")

        y_train = y_train_dict[company]
        X_test = X_test_dict[company]
        y_test = y_test_dict[company]

        train_dataset = StockDataset(X_train, y_train, seq_len, batch_size)
        test_dataset = StockDataset(X_test, y_test, seq_len, batch_size)

        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

        model = TransformerStockPredictor(**model_params).to(device)

        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)

        for epoch in range(epochs):
            model.train()
            train_loss = 0.0

            for x_batch, y_batch in train_loader:
                x_batch, y_batch = x_batch.to(device), y_batch.to(device)

                optimizer.zero_grad()
                predictions = model(x_batch).squeeze(-1)
                loss = criterion(predictions, y_batch)
                loss.backward()
                optimizer.step()

                train_loss += loss.item()

            train_loss /= len(train_loader)

            model.eval()
            test_loss = 0.0
            with torch.no_grad():
                for x_test, y_test in test_loader:
                    x_test, y_test = x_test.to(device), y_test.to(device)
                    predictions = model(x_test).squeeze(-1)
                    loss = criterion(predictions, y_test)
                    test_loss += loss.item()

            test_loss /= len(test_loader)
            print(f"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}")

        model_save_path = f"{save_dir}/{company}_model.pth"
        torch.save(model.state_dict(), model_save_path)
        print(f"Model for {company} saved to {model_save_path}")

        trained_models[company] = model

    return trained_models

model_params = {
    "input_dim": 4,
    "seq_len": 20,
    "d_model": 96,
    "n_heads": 3,
    "n_encoders": 2,
    "ff_dim": 128,
    "dropout": 0.2
}

trained_models = train_models_without_saving(
    X_train_dict=X_train_dict,
    y_train_dict=y_train_dict,
    X_test_dict=X_test_dict,
    y_test_dict=y_test_dict,
    seq_len=20,
    model_params=model_params,
    epochs=30,
    lr=1e-3,
    batch_size=16
)



import os

def save_models_with_paths(trained_models, save_dir):
    """
    Save models and store their paths in a dictionary.
    Creates the parent directory if it doesn't exist.
    """
    os.makedirs(save_dir, exist_ok=True)

    print(f"Saving models to: {os.path.abspath(save_dir)}")

    model_paths = {}
    for company, model in trained_models.items():
        model_path = os.path.join(save_dir, f"{company}_model.pth")
        torch.save(model.state_dict(), model_path)
        model_paths[company] = model_path
    return model_paths

save_dir = './models'
model_paths = save_models_with_paths(trained_models, save_dir)
print("Saved model paths:", model_paths)

import os

def get_model_paths(save_dir, companies):
    """
    Returns a list of file paths for the saved models of each company.
    """
    model_paths = []
    for company in companies:
        model_path = os.path.join(save_dir, f"{company}_model.pth")
        if os.path.exists(model_path):
            model_paths.append(model_path)
        else:
            print(f"Model for {company} not found at {model_path}")
    return model_paths

companies = ['Apple', 'Pfizer', 'Wells', 'Amazon', 'Tesla']
save_dir = './models'

model_paths = get_model_paths(save_dir, companies)
print("Model file paths:", model_paths)

from google.colab import files
import shutil

def download_model(model_path):
    """
    Download the model file from Colab to the local machine.
    """
    shutil.copy(model_path, '/content/')

    files.download('/content/' + model_path.split('/')[-1])

model_paths = ['./models/Apple_model.pth', './models/Amazon_model.pth','./models/Tesla_model.pth', './models/Wells_model.pth','./models/Pfizer_model.pth']  # List of model paths
for model_path in model_paths:
    download_model(model_path)

df1.head()

from google.colab import files

csv_file = "/content/AAPL.csv"  # Specify the path
df1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/AMZN.csv"  # Specify the path
df1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/PFE.csv"  # Specify the path
df1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/TSLA.csv"  # Specify the path
df1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/WFC.csv"  # Specify the path
df1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/AMZN.csv"  # Specify the path
d2.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/WFC.csv"  # Specify the path
d3.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/TSLA.csv"  # Specify the path
d4.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/PFE.csv"  # Specify the path
d1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

import yfinance as yf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np




stock1 = yf.Ticker("AAPL")
data1 = stock1.history(start='2010-12-24',end='2024-12-24',interval='1d')
data1.to_csv("AAPL2.csv")

stock2 = yf.Ticker("AMZN")
data2 = stock2.history(start='2010-12-24',end='2024-12-24',interval='1d')
data2.to_csv("AMZN2.csv")

stock3 = yf.Ticker("WFC")
data3 = stock3.history(start='2010-12-24',end='2024-12-24',interval='1d')
data3.to_csv("WFC2.csv")

stock4 = yf.Ticker("TSLA")
data4 = stock4.history(start='2010-12-24',end='2024-12-24',interval='1d')
data4.to_csv("TSLA2.csv")

stock5 = yf.Ticker("PFE")
data5 = stock5.history(start='2010-12-24',end='2024-12-24',interval='1d')
data1.to_csv("PFE2.csv")

dd1=pd.read_csv('AAPL2.csv')
dd2=pd.read_csv('AMZN2.csv')
dd3=pd.read_csv('WFC2.csv')
dd4=pd.read_csv('TSLA2.csv')
dd5=pd.read_csv('PFE2.csv')

from google.colab import files

csv_file = "/content/AAPL2.csv"  # Specify the path
dd1.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/AMZN2.csv"  # Specify the path
dd2.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

csv_file = "/content/WFC2.csv"  # Specify the path
dd3.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)
csv_file = "/content/TSLA2.csv"  # Specify the path
dd4.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)
csv_file = "/content/PFE2.csv"  # Specify the path
dd5.to_csv(csv_file, index=False)

# Download the CSV file
files.download(csv_file)

